{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 21, **BEFORE the beginning of class at 6:00pm**\n",
    "\n",
    "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "    member 1\n",
    "    \n",
    "    member 2\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x1088725f8>\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "\n",
    "CONSUMER_KEY = 'V6PEvWJ1XPiSEzm9kXuDo9aj6'\n",
    "CONSUMER_SECRET ='kjoSvNFKCNCzTbqWFlkw1BOvlJoMt2OQO3zF9J3z1SYBmXQTQ2'\n",
    "OAUTH_TOKEN = '892990835062489092-Wq2zWKVBb2RVrmeIF5Q0JWioJV5Sv7R'\n",
    "OAUTH_TOKEN_SECRET = 'MggsyF0VndpDIllIqcbxUHfRJ0dJdd9FWWqiNKEr1oYXy'\n",
    "    \n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "print(twitter_api)\n",
    "\n",
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipykernel.iostream.OutStream object at 0x10883efd0> Filtering the public timeline for track=\"bikeshare\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import twitter\n",
    "\n",
    "# Query terms\n",
    "\n",
    "q = 'bikeshare' # Comma-separated list of terms\n",
    "\n",
    "\n",
    "\n",
    "print(sys.stderr, 'Filtering the public timeline for track=\"%s\"' % (q,))\n",
    "sys.stderr.flush()\n",
    "\n",
    "# Returns an instance of twitter.Twitter\n",
    "\n",
    "# Reference the self.auth parameter\n",
    "twitter_stream = twitter.TwitterStream(auth=twitter_api.auth)\n",
    "\n",
    "# See https://dev.twitter.com/docs/streaming-apis\n",
    "stream = twitter_stream.statuses.filter(track=q)\n",
    "\n",
    "# For illustrative purposes, when all else fails, search for Justin Bieber\n",
    "# and something is sure to turn up (at least, on Twitter)\n",
    "\n",
    "for tweet in stream:\n",
    "    print(tweet['text'])\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Save to a database in a particular collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of statuses 100\n",
      "Length of statuses 200\n",
      "Length of statuses 300\n",
      "Length of statuses 400\n",
      "Length of statuses 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "q = 'bikeshare'\n",
    "\n",
    "count = 500\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "\n",
    "statuses = search_results['statuses']\n",
    "\n",
    "\n",
    "# Iterate through 5 more batches of results by following the cursor\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"Length of statuses\", len(statuses))\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "    except KeyError: # No more results when next_results doesn't exist\n",
    "        break\n",
    "        \n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "    kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n",
    "    \n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "# Show one sample search result by slicing the list...\n",
    "print(json.dumps(statuses, indent=4))\n",
    "\n",
    "data= json.dumps(statuses, indent=4)\n",
    "\n",
    "file = open('problem1.txt','w')\n",
    "file.write(data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: < INSERT YOUR TOPIC HERE>\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  < INSERT THE NUMBER HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RT', 269), ('the', 209), ('to', 200), ('in', 154), ('bikeshare', 141), ('of', 138), ('@bikeshare', 136), ('for', 115), ('#bikeshare', 115), ('a', 114), ('dockless', 99), ('is', 88), ('&amp;', 76), ('new', 74), ('I', 58), ('on', 55), ('has', 52), ('with', 50), ('DC', 50), ('and', 50), ('you', 47), ('A', 41), ('-', 39), ('at', 38), ('from', 37), ('bikes', 36), ('@MobikeUSA', 34), ('@ggwash', 34), ('Bikeshare', 34), ('bike', 33)]\n",
      "[('bikeshare', 170), ('ggwash', 41), ('MobikeUSA', 38), ('limebike', 38), ('spincities', 29), ('alpert', 26), ('BrentToderian', 18), ('FairmontWF', 18), ('Mobike', 15), ('DDOTDC', 14), ('wmata', 14), ('sharrowsDC', 12), ('rkishorenitc', 12), ('CECHR_UoD', 11), ('MartinDiCaro', 11), ('DCist', 11), ('MNiessenPhoto', 10), ('Wash_cycle', 9), ('joanneliveshere', 9), ('THEARC_DC', 8), ('wamu885', 8), ('GovernorVA', 7), ('mattmcfarland', 6), ('PeggyTV', 6), ('FriendsofMP', 6), ('bhopal_bscdcl', 6), ('GreenAU', 6), ('SecBurwell', 6), ('KristajSharpe', 6), ('SouthSimcoePS', 6)]\n",
      "[('bikeshare', 117), ('BikeShare', 34), ('bikedc', 24), ('Vancouver', 19), ('bikes', 15), ('bicycles', 11), ('red', 11), ('closeup', 11), ('CDMX', 11), ('dockless', 10), ('bikesharing', 10), ('DC', 9), ('Dockless', 8), ('ebike', 7), ('Bhopal', 7), ('transport', 6), ('app', 6), ('Bikesharing', 6), ('UnlockGridlock', 6), ('LessCars', 5), ('carshare', 5), ('ebikes', 4), ('BikeDC', 4), ('TfL', 4), ('Transport', 4), ('London', 4), ('NYC', 4), ('BikeShareGoals', 4), ('bikeDC', 4), ('TakomaPark', 4)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    print(c.most_common()[:30]) # top 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "| Word       | Count |\n",
      "+------------+-------+\n",
      "| RT         |   269 |\n",
      "| the        |   209 |\n",
      "| to         |   200 |\n",
      "| in         |   154 |\n",
      "| bikeshare  |   141 |\n",
      "| of         |   138 |\n",
      "| @bikeshare |   136 |\n",
      "| for        |   115 |\n",
      "| #bikeshare |   115 |\n",
      "| a          |   114 |\n",
      "| dockless   |    99 |\n",
      "| is         |    88 |\n",
      "| &amp;      |    76 |\n",
      "| new        |    74 |\n",
      "| I          |    58 |\n",
      "| on         |    55 |\n",
      "| has        |    52 |\n",
      "| with       |    50 |\n",
      "| DC         |    50 |\n",
      "| and        |    50 |\n",
      "| you        |    47 |\n",
      "| A          |    41 |\n",
      "| -          |    39 |\n",
      "| at         |    38 |\n",
      "| from       |    37 |\n",
      "| bikes      |    36 |\n",
      "| @MobikeUSA |    34 |\n",
      "| @ggwash    |    34 |\n",
      "| Bikeshare  |    34 |\n",
      "| bike       |    33 |\n",
      "+------------+-------+\n",
      "+-----------------+-------+\n",
      "| Screen Name     | Count |\n",
      "+-----------------+-------+\n",
      "| bikeshare       |   170 |\n",
      "| ggwash          |    41 |\n",
      "| MobikeUSA       |    38 |\n",
      "| limebike        |    38 |\n",
      "| spincities      |    29 |\n",
      "| alpert          |    26 |\n",
      "| BrentToderian   |    18 |\n",
      "| FairmontWF      |    18 |\n",
      "| Mobike          |    15 |\n",
      "| DDOTDC          |    14 |\n",
      "| wmata           |    14 |\n",
      "| sharrowsDC      |    12 |\n",
      "| rkishorenitc    |    12 |\n",
      "| CECHR_UoD       |    11 |\n",
      "| MartinDiCaro    |    11 |\n",
      "| DCist           |    11 |\n",
      "| MNiessenPhoto   |    10 |\n",
      "| Wash_cycle      |     9 |\n",
      "| joanneliveshere |     9 |\n",
      "| THEARC_DC       |     8 |\n",
      "| wamu885         |     8 |\n",
      "| GovernorVA      |     7 |\n",
      "| mattmcfarland   |     6 |\n",
      "| PeggyTV         |     6 |\n",
      "| FriendsofMP     |     6 |\n",
      "| bhopal_bscdcl   |     6 |\n",
      "| GreenAU         |     6 |\n",
      "| SecBurwell      |     6 |\n",
      "| KristajSharpe   |     6 |\n",
      "| SouthSimcoePS   |     6 |\n",
      "+-----------------+-------+\n",
      "+----------------+-------+\n",
      "| Hashtag        | Count |\n",
      "+----------------+-------+\n",
      "| bikeshare      |   117 |\n",
      "| BikeShare      |    34 |\n",
      "| bikedc         |    24 |\n",
      "| Vancouver      |    19 |\n",
      "| bikes          |    15 |\n",
      "| bicycles       |    11 |\n",
      "| red            |    11 |\n",
      "| closeup        |    11 |\n",
      "| CDMX           |    11 |\n",
      "| dockless       |    10 |\n",
      "| bikesharing    |    10 |\n",
      "| DC             |     9 |\n",
      "| Dockless       |     8 |\n",
      "| ebike          |     7 |\n",
      "| Bhopal         |     7 |\n",
      "| transport      |     6 |\n",
      "| app            |     6 |\n",
      "| Bikesharing    |     6 |\n",
      "| UnlockGridlock |     6 |\n",
      "| LessCars       |     5 |\n",
      "| carshare       |     5 |\n",
      "| ebikes         |     4 |\n",
      "| BikeDC         |     4 |\n",
      "| TfL            |     4 |\n",
      "| Transport      |     4 |\n",
      "| London         |     4 |\n",
      "| NYC            |     4 |\n",
      "| BikeShareGoals |     4 |\n",
      "| bikeDC         |     4 |\n",
      "| TakomaPark     |     4 |\n",
      "+----------------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in  (('Word', words), \n",
    "                     ('Screen Name', screen_names), \n",
    "                     ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:30] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+----------------------------------------------------+\n",
      "| Count | Screen Name | Text                                               |\n",
      "+-------+-------------+----------------------------------------------------+\n",
      "| 56    | jenipherzjw | RT @jenipherzjw: #Walking &amp; #Biking call for   |\n",
      "|       |             | #innovations of smart #Transportation #Tech for    |\n",
      "|       |             | Safety &amp; Mobility https://t.co/9R6UxJ99LT      |\n",
      "|       |             | #Bik…                                              |\n",
      "| 56    | jenipherzjw | RT @jenipherzjw: #Walking &amp; #Biking call for   |\n",
      "|       |             | #innovations of smart #Transportation #Tech for    |\n",
      "|       |             | Safety &amp; Mobility https://t.co/9R6UxJ99LT      |\n",
      "|       |             | #Bik…                                              |\n",
      "| 56    | jenipherzjw | RT @jenipherzjw: #Walking &amp; #Biking call for   |\n",
      "|       |             | #innovations of smart #Transportation #Tech for    |\n",
      "|       |             | Safety &amp; Mobility https://t.co/9R6UxJ99LT      |\n",
      "|       |             | #Bik…                                              |\n",
      "| 39    | ATTBusiness | RT @ATTBusiness: A bikeshare service that's also   |\n",
      "|       |             | station free? Proud to provide #IoT solutions to   |\n",
      "|       |             | @MobikeUSA  w/ @Qualcomm : https://t.co/u…         |\n",
      "| 39    | ATTBusiness | RT @ATTBusiness: A bikeshare service that's also   |\n",
      "|       |             | station free? Proud to provide #IoT solutions to   |\n",
      "|       |             | @MobikeUSA  w/ @Qualcomm : https://t.co/u…         |\n",
      "| 27    | joeflood    | RT @joeflood: everybody bikeshares - even juggalos |\n",
      "|       |             | @bikeshare #bikedc https://t.co/CSHIid1KNR         |\n",
      "| 23    | FriendsofMP | RT @FriendsofMP: In short duration, Bhopal's       |\n",
      "|       |             | #BikeShare System has crossed 20,000 registrations |\n",
      "|       |             | making India's best Cycle Share System. #Na…       |\n",
      "| 23    | FriendsofMP | RT @FriendsofMP: In short duration, Bhopal's       |\n",
      "|       |             | #BikeShare System has crossed 20,000 registrations |\n",
      "|       |             | making India's best Cycle Share System. #Na…       |\n",
      "| 23    | FriendsofMP | RT @FriendsofMP: In short duration, Bhopal's       |\n",
      "|       |             | #BikeShare System has crossed 20,000 registrations |\n",
      "|       |             | making India's best Cycle Share System. #Na…       |\n",
      "| 23    | FriendsofMP | RT @FriendsofMP: In short duration, Bhopal's       |\n",
      "|       |             | #BikeShare System has crossed 20,000 registrations |\n",
      "|       |             | making India's best Cycle Share System. #Na…       |\n",
      "+-------+-------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "retweets = [\n",
    "            # Store out a tuple of these three values ...\n",
    "            (status['retweet_count'], \n",
    "             status['retweeted_status']['user']['screen_name'],\n",
    "             status['text']) \n",
    "            \n",
    "            # ... for each status ...\n",
    "            for status in statuses \n",
    "            \n",
    "            # ... so long as the status meets this condition.\n",
    "                if 'retweeted_status' in status\n",
    "           ]\n",
    "\n",
    "# Slice off the first 10 from the sorted results and display each item in the tuple\n",
    "\n",
    "pt = PrettyTable(field_names=['Count', 'Screen Name', 'Text'])\n",
    "[ pt.add_row(row) for row in sorted(retweets, reverse=True)[:10] ]\n",
    "pt.max_width['Text'] = 50\n",
    "pt.align= 'l'\n",
    "print(pt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " \"RT @BrentToderian: A sign of the times - Downtown #Vancouver's @FairmontWF Hotel replaces entrance water feature with revolving free #bikes\\u2026\",\n",
      " \"RT @ATTBusiness: A bikeshare service that's also station free? Proud to provide #IoT solutions to @MobikeUSA  w/ @Qualcomm : https://t.co/u\\u2026\",\n",
      " \"RT @cdempc: Arlington residents should be excited about exploration of dockless bikeshare by @AdamWChap + team: https://t.co/bSGoKH9Lin\",\n",
      " \"RT @ATTBusiness: A bikeshare service that's also station free? Proud to provide #IoT solutions to @MobikeUSA  w/ @Qualcomm : https://t.co/u\\u2026\",\n",
      " \"What you need to know about the three(!) new dock-free bikeshare pilots in DC https://t.co/0dR0Pc1suD\",\n",
      " \"Arlington residents should be excited about exploration of dockless bikeshare by @AdamWChap + team: https://t.co/bSGoKH9Lin\",\n",
      " \"RT @morbrem: This is a great opportunity for Dems to grandstand but if they havent screamed for expanded Circluator&amp;Bikeshare, they are a p\\u2026\",\n",
      " \"@CityLab Dockless bike share is killing it in Seattle. https://t.co/ej89bQAt9p\",\n",
      " \"RT @jumpmobility: DC! Your dockless e-bikes have arrived. Launching 9/25. #bikedc #ebikes #bikeshare https://t.co/lkVy3Dw3qp\",\n",
      " \"RT @dan_majewski: The wonderful wild world of #bikeshare is really exciting these days! https://t.co/MTvlP17dVD\"\n",
      "]\n",
      "[\n",
      " \"BrentToderian\",\n",
      " \"FairmontWF\",\n",
      " \"ATTBusiness\",\n",
      " \"MobikeUSA\",\n",
      " \"Qualcomm\",\n",
      " \"cdempc\",\n",
      " \"AdamWChap\",\n",
      " \"ATTBusiness\",\n",
      " \"MobikeUSA\",\n",
      " \"Qualcomm\"\n",
      "]\n",
      "[\n",
      " \"Vancouver\",\n",
      " \"IoT\",\n",
      " \"IoT\",\n",
      " \"bikedc\",\n",
      " \"ebikes\",\n",
      " \"bikeshare\",\n",
      " \"bikeshare\",\n",
      " \"CarFreeDay\",\n",
      " \"bikeshare\",\n",
      " \"bikedc\"\n",
      "]\n",
      "[\n",
      " \"RT\",\n",
      " \"@BrentToderian:\",\n",
      " \"A\",\n",
      " \"sign\",\n",
      " \"of\",\n",
      " \"the\",\n",
      " \"times\",\n",
      " \"-\",\n",
      " \"Downtown\",\n",
      " \"#Vancouver's\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "# Explore the first 5 items for each...\n",
    "\n",
    "print(json.dumps(status_texts[0:10], indent=1))\n",
    "print(json.dumps(screen_names[0:10], indent=1))\n",
    "print(json.dumps(hashtags[0:10], indent=1))\n",
    "print(json.dumps(words[0:10], indent=1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "| Word       | Count |\n",
      "+------------+-------+\n",
      "| RT         |   269 |\n",
      "| the        |   209 |\n",
      "| to         |   200 |\n",
      "| in         |   154 |\n",
      "| bikeshare  |   141 |\n",
      "| of         |   138 |\n",
      "| @bikeshare |   136 |\n",
      "| for        |   115 |\n",
      "| #bikeshare |   115 |\n",
      "| a          |   114 |\n",
      "+------------+-------+\n",
      "+---------------+-------+\n",
      "| Screen Name   | Count |\n",
      "+---------------+-------+\n",
      "| bikeshare     |   170 |\n",
      "| ggwash        |    41 |\n",
      "| MobikeUSA     |    38 |\n",
      "| limebike      |    38 |\n",
      "| spincities    |    29 |\n",
      "| alpert        |    26 |\n",
      "| BrentToderian |    18 |\n",
      "| FairmontWF    |    18 |\n",
      "| Mobike        |    15 |\n",
      "| DDOTDC        |    14 |\n",
      "+---------------+-------+\n",
      "+-----------+-------+\n",
      "| Hashtag   | Count |\n",
      "+-----------+-------+\n",
      "| bikeshare |   117 |\n",
      "| BikeShare |    34 |\n",
      "| bikedc    |    24 |\n",
      "| Vancouver |    19 |\n",
      "| bikes     |    15 |\n",
      "| bicycles  |    11 |\n",
      "| red       |    11 |\n",
      "| closeup   |    11 |\n",
      "| CDMX      |    11 |\n",
      "| dockless  |    10 |\n",
      "+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in  (('Word', words), \n",
    "                    ('Screen Name', screen_names), \n",
    "                    ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import time \n",
    "\n",
    "CONSUMER_KEY = 'GbHv0cWq5PnBNSu4XHvLhAyLG'\n",
    "CONSUMER_SECRET ='74ZC6wf1bpVtUZ9fFfqg6sqsKr1ceRUM6vDv1wAgH2Iq06zanf'\n",
    "OAUTH_TOKEN = '751729863317336065-zwRvRjmLNeFnCbQMmswysIFG084n7nO'\n",
    "OAUTH_TOKEN_SECRET = 'ZUPGdMrYP6vzsPV8BNC5bNJ2IspuqpxkIy1zBnlzZUrH2'\n",
    "\n",
    "auth = OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN,OAUTH_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "#accountvar = raw_input(\"Kevin Durant\")\n",
    "\n",
    "users = tweepy.Cursor(api.followers_ids,screen_name=\"KDTrey5\",count=5000).items()\n",
    "\n",
    "F = open('followers.txt','w')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user = next(users)\n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60)\n",
    "        user = next(users)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    print(user,file=F)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "friends = tweepy.Cursor(api.friends_ids,screen_name=\"KDTrey5\",count=5000).items()\n",
    "\n",
    "f = open('friends.txt','w')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user = next(friends)\n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60)\n",
    "        user = next(friends)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    print(user,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "| id                 |     screen_name |\n",
      "+--------------------+-----------------+\n",
      "| 707417505413799936 |    CartsOfPCArl |\n",
      "| 383745751          |    Daina_Ardila |\n",
      "| 334116743          |     MinetaTrans |\n",
      "| 271724323          |          BEandT |\n",
      "| 875007600785584129 |  thealbatrossss |\n",
      "| 319082942          |      alexgdodds |\n",
      "| 910468867620716544 | WatchdogMichael |\n",
      "| 51639960           |        reeveskd |\n",
      "| 894729397713948672 |       El19Anwar |\n",
      "| 4165078409         | NVTATransAction |\n",
      "| 127322296          |          kaj428 |\n",
      "| 1895881891         |   the_benjammin |\n",
      "| 420676150          |        SandyP92 |\n",
      "| 885910906458255361 |    jessiegarber |\n",
      "| 15949714           |       juliewood |\n",
      "| 85727724           |    belleplanner |\n",
      "| 431871482          |    NordquistUSA |\n",
      "| 65232608           | jordanschreiber |\n",
      "| 90692969           |     kacykostiuk |\n",
      "| 155982556          | DarkJediMaster2 |\n",
      "+--------------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving user ids to screen names: 20/20\n"
     ]
    }
   ],
   "source": [
    "#Find followers of KD\n",
    "from twitter import follow\n",
    "\n",
    "fl = open('followers.txt')\n",
    "lines = fl.readlines()\n",
    "followers_ids = [id_item.strip() for id_item in lines] \n",
    "\n",
    "followers_dict = follow.lookup(twitter_api, user_ids=followers_ids[:20])\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "pt = PrettyTable(field_names=['id', 'screen_name'])\n",
    "for follower_id in followers_dict:\n",
    "    screen_name = followers_dict[follower_id]\n",
    "    pt.add_row([follower_id, screen_name])\n",
    "    pt.align['id'], pt.align['screen_name'] = 'l', 'r' # Set column alignment\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "| id                 |     screen_name |\n",
      "+--------------------+-----------------+\n",
      "| 13192972           |       AlaskaAir |\n",
      "| 2382584922         |  OprahSideNigga |\n",
      "| 380486714          |     _KinGStunT_ |\n",
      "| 35586563           |      jemelehill |\n",
      "| 311553919          |   JustinEvans05 |\n",
      "| 884344425396162562 |     RipCityGoon |\n",
      "| 2698660387         |       rubrikInc |\n",
      "| 36831984           |        eoe_COOP |\n",
      "| 35831704           |        MrChuckD |\n",
      "| 181572333          | chancetherapper |\n",
      "| 26270913           |        warriors |\n",
      "| 1388642136         |        NBAIndia |\n",
      "| 4564195402         |         LiamNBA |\n",
      "| 3282859598         |    TwitterVideo |\n",
      "| 14423603           |      beatsbydre |\n",
      "| 10228272           |         YouTube |\n",
      "| 74594552           |        AppStore |\n",
      "| 78525538           |         IssaRae |\n",
      "| 170759111          |        L_Bell26 |\n",
      "| 42040091           | Chris_Broussard |\n",
      "+--------------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving user ids to screen names: 20/20\n"
     ]
    }
   ],
   "source": [
    "#Find friends of KD\n",
    "fr = open('friends.txt')\n",
    "lines = fr.readlines()\n",
    "friends_ids = [id_item.strip() for id_item in lines] \n",
    "\n",
    "friends_dict = follow.lookup(twitter_api, user_ids=friends_ids[:20])\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "pt = PrettyTable(field_names=['id', 'screen_name'])\n",
    "for friend_id in friends_dict:\n",
    "    screen_name = friends_dict[friend_id]\n",
    "    pt.add_row([friend_id, screen_name])\n",
    "    pt.align['id'], pt.align['screen_name'] = 'l', 'r' # Set column alignment\n",
    "print(pt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "| id | screen_name |\n",
      "+----+-------------+\n",
      "+----+-------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving user ids to screen names: 2/2\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "with open('friends.txt') as fr:\n",
    "    lines = fr.readlines()\n",
    "firends_ids = [id_item.strip() for id_item in lines]\n",
    "\n",
    "# traverse 'followers' list，decide if it exists in 'friends' list\n",
    "fl = open('followers.txt')\n",
    "line = fl.readline()\n",
    "common_ids = []\n",
    "while line:\n",
    "    follower_id = line.strip()\n",
    "    if follower_id in friends_ids:\n",
    "        common_ids.append(follower_id)\n",
    "    line = fl.readline()\n",
    "\n",
    "common_dict = follow.lookup(twitter_api, user_ids=common_ids)\n",
    "#followers_dict = follow.lookup(twitter_api, user_ids=followers_ids[:friends_limit])\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "pt = PrettyTable(field_names=['id', 'screen_name'])\n",
    "for common_id in common_dict:\n",
    "    screen_name = common_dict[common_id]\n",
    "    pt.align['id'], pt.align['screen_name'] = 'l', 'r' # Set column alignment\n",
    "print(pt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see file Problem 4 attached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "\n",
    "#### We auto-process the submissions so make sure your subject line is *exactly*:\n",
    "\n",
    "### DS501 Case Study 1 Team ??\n",
    "\n",
    "#### where ?? is your team number.\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
