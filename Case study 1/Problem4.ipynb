{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#search tweets according to search targetï¼Œdo preference analysis\n",
    "import twitter\n",
    "import json\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "\n",
    "def oauth_login():\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = '5Pd25XKxJkdNUIm0LoDGxfNTB'\n",
    "    CONSUMER_SECRET ='KQodfRCfkvDdDuQtafFwwvrsS1Q9uk5t3CznR9T5UkP3nwOdDu'\n",
    "    OAUTH_TOKEN = '909871523447607298-G483xW9bSLv2RqZYlr3AZ4yb9gnUW7A'\n",
    "    OAUTH_TOKEN_SECRET = '1DQ2DNiGip1IzhYJEbry1HAGKB2bPXE0HDOFIQs5Uouqw'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "search_target = [['Citi Bike','New York','NYC'],['Capital Bike','Washington','DC'],['Citi Bike','Miami',''],['Divvy','Chicago',''],\n",
    "                 ['Hubway','Boston',''],['lime','Seattle',''],['lime','Dallas',''],['lime','San Francisco','\"Bay Area\"'],\n",
    "                 ['lime','South Lake Tahoe',''],['lime','Key Biscayne',''],['lime','South Bend',''],['lime','Greensboro',''],\n",
    "                 ['lime','Imperial Beach',''],['ofo','Seattle',''],['ofo','Worcester',''],['SpinBike','Seattle',''],\n",
    "                 ['SpinBike','Washington','DC'],['Mobike','Washington','DC'],['bluegogo','San Francisco','\"Bay Area\"']]\n",
    "\n",
    "sentiment = []\n",
    "\n",
    "count = 100\n",
    "\n",
    "for item in search_target:\n",
    "    q = item[0]+' '+item[1]       \n",
    "    #begin search\n",
    "    search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "    statuses = search_results['statuses']\n",
    "\n",
    "    for _ in range(5):\n",
    "      #  print(\"Length of statuses\", len(statuses))\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError: # No more results when next_results doesn't exist\n",
    "            break\n",
    "        \n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n",
    "    \n",
    "        search_results = oauth_login().search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "    status_texts = [ status['text'] \n",
    "                     for status in statuses ]\n",
    "    text = json.dumps(status_texts, indent = 1)\n",
    "\n",
    "    blob1 = TextBlob(text)\n",
    "    i = [q,len(statuses),blob1.sentiment.polarity]\n",
    "\n",
    "    sentiment.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Citi Bike New York', 200, 0.5161317953403365], ['Capital Bike Washington', 4, 0.21428571428571427], ['Citi Bike Miami', 5, 0.4600000000000001], ['Divvy Chicago', 30, 0.41015625], ['Hubway Boston', 31, 0.39263975966562176], ['lime Seattle', 27, 0.1025974025974026], ['lime Dallas', 11, 0.11750000000000001], ['lime San Francisco', 6, 0.16], ['lime South Lake Tahoe', 0, 0.0], ['lime Key Biscayne', 0, 0.0], ['lime South Bend', 0, 0.0], ['lime Greensboro', 2, 0.0], ['lime Imperial Beach', 2, 0.0], ['ofo Seattle', 115, 0.16600328947368417], ['ofo Worcester', 97, 0.32120329352850546], ['SpinBike Seattle', 0, 0.0], ['SpinBike Washington', 0, 0.0], ['Mobike Washington', 141, 0.23143552875695741], ['bluegogo San Francisco', 0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment)\n",
    "# the first part of the result is the key word,.\n",
    "# the second part is the point of preference analysis, the higher the point is, the more they prefer the key word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "w = re.split(r'[\\s\\,\\;\\:\\n\\\"\\[\\]\\\\\\#\\.]+', json.dumps(words,indent=1)) #Use regular expression to get a clear word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get American Cities list\n",
    "cities = []\n",
    "f  = open('/Users/weiqingli/Downloads/PEP_2016_PEPANNRSIP.US12A/americacities.csv')\n",
    "for line in f.readlines():\n",
    "    line = line.strip('\\n')\n",
    "    line = line.rstrip()\n",
    "    cities.append(line)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "| City name  | Count |\n",
      "+------------+-------+\n",
      "| Seattle    |    13 |\n",
      "| Washington |     9 |\n",
      "| Arlington  |     5 |\n",
      "| Baltimore  |     5 |\n",
      "| Rochester  |     4 |\n",
      "| Orange     |     3 |\n",
      "| Savannah   |     3 |\n",
      "| National   |     3 |\n",
      "| Hoboken    |     2 |\n",
      "| Georgetown |     1 |\n",
      "| Meridian   |     1 |\n",
      "| Manchester |     1 |\n",
      "| Manhattan  |     1 |\n",
      "| Boston     |     1 |\n",
      "| League     |     1 |\n",
      "| Raleigh    |     1 |\n",
      "| Union      |     1 |\n",
      "| Layton     |     1 |\n",
      "+------------+-------+\n"
     ]
    }
   ],
   "source": [
    "#Analysis of the counts of each city that was refered in the tweets\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "word_city = []\n",
    "\n",
    "for i in w:\n",
    "    if i in cities:\n",
    "        word_city.append(i)\n",
    "\n",
    "pt = PrettyTable(['City name','Count']) \n",
    "c = Counter(word_city)\n",
    "[ pt.add_row(kv) for kv in c.most_common()]\n",
    "pt.align['City name'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "print(pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
